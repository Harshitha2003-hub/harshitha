{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c45xudyBOoKM",
        "outputId": "a9b6ea25-703e-48f7-88a7-c4f0b25635bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   sepal length (cm)  150 non-null    float64\n",
            " 1   sepal width (cm)   150 non-null    float64\n",
            " 2   petal length (cm)  150 non-null    float64\n",
            " 3   petal width (cm)   150 non-null    float64\n",
            " 4   species            150 non-null    int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 6.0 KB\n",
            "None\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   species  \n",
            "0        0  \n",
            "1        0  \n",
            "2        0  \n",
            "3        0  \n",
            "4        0  \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Data Loading and Exploration\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris_data = load_iris()\n",
        "\n",
        "# Convert to a DataFrame\n",
        "import pandas as pd\n",
        "iris_df = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)\n",
        "iris_df['species'] = iris_data.target\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(iris_df.info())\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(iris_df.head())\n",
        "# Step 2: Data Preprocessing\n",
        "# Feature scaling (optional but can improve model performance)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(iris_df.drop('species', axis=1))\n",
        "\n",
        "# Convert back to DataFrame\n",
        "scaled_df = pd.DataFrame(data=scaled_features, columns=iris_df.columns[:-1])\n",
        "scaled_df['species'] = iris_df['species']\n",
        "# Step 3: Model Selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = scaled_df.drop('species', axis=1)\n",
        "y = scaled_df['species']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the K-Nearest Neighbors classifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "\n",
        "# Step 4: Model Training\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Model Evaluation\n",
        "# Make predictions on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    }
  ]
}